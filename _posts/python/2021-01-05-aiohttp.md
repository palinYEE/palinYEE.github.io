---
layout: post
title:  "[PYTHON] aiohttp를 사용해보자. "
date:   2021-01-05T18:09:52-05:00
author: 윤영진
categories: python
tags: python crawling network
cover:  "/assets/instacode.png"
---
# 알아야 하는 이유

우리가 웹에서 데이터를 수집해 올때, 파이썬의 크롤링을 이용하게 된다. 이때 다음과 같은 상황을 생각해 보자!

<center> 수많은 웹 사이트를 크롤링 해야 한다.</center>

이럴때 우리가 원래 알고 있는 `request` 함수를 사용하게 되면 매우 느릴 것이다. 그러면 이러한 속도 문제에서 어느정도 벗어나기 위해서는 비동기 방식으로 크롤링을 해야 한다. 

이때, 비동기 방식에서 웹 통신을 할 수 있게 해주는 놈이 바로 `aiohttp` 이다. 

# 그래서 aiohttp가 뭔데..

aiohttp는 Python 3.4부터 표준 라이브러리로 추가된 asyncio (PEP3156) 를 위한 HTTP 서버/클라이언트 프레임워크이다.

# 예제 코드

```
import aiohttp, asyncio


async def crawling(url):
    print(f'[*] Start crawling {url}')

    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
        async with session.get(url, headers={'user-agent': 'Mozilla/5.0'}) as response:
            print(f'[-] {url} status : {response.status}')

async def main():
    base_url = 'https://www.macmillandictionary.com/us/dictionary/american/{keyword}'
    keywords = ['hello', 'bye', 'like', 'love', 'environmental',
                'buzz', 'ambition', 'determine']

    task = [asyncio.ensure_future(crawling(base_url.format(keyword=keyword))) for keyword in keywords]

    await asyncio.gather(*task)

if __name__=="__main__":
    print('[*] aiohttp example start')

    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())

    print('[*] finish')
```
